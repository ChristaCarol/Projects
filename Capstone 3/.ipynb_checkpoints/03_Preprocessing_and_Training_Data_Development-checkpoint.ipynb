{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a685eb1-ed7b-4ca2-a09a-4118a52aa831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index             Order ID      Date                        Status  \\\n",
      "0      0  405-8078784-5731545  04-30-22                     Cancelled   \n",
      "1      1  171-9198151-1101146  04-30-22  Shipped - Delivered to Buyer   \n",
      "2      2  404-0687676-7273146  04-30-22                       Shipped   \n",
      "3      3  403-9615377-8133951  04-30-22                     Cancelled   \n",
      "4      4  407-1069790-7240320  04-30-22                       Shipped   \n",
      "\n",
      "  Fulfilment Sales Channel  ship-service-level    Style              SKU  \\\n",
      "0   Merchant      Amazon.in           Standard   SET389   SET389-KR-NP-S   \n",
      "1   Merchant      Amazon.in           Standard  JNE3781  JNE3781-KR-XXXL   \n",
      "2     Amazon      Amazon.in          Expedited  JNE3371    JNE3371-KR-XL   \n",
      "3   Merchant      Amazon.in           Standard    J0341       J0341-DR-L   \n",
      "4     Amazon      Amazon.in          Expedited  JNE3671  JNE3671-TU-XXXL   \n",
      "\n",
      "        Category  ...  Amount    ship-city   ship-state  ship-postal-code  \\\n",
      "0            Set  ...  647.62       MUMBAI  MAHARASHTRA          400081.0   \n",
      "1          kurta  ...  406.00    BENGALURU    KARNATAKA          560085.0   \n",
      "2          kurta  ...  329.00  NAVI MUMBAI  MAHARASHTRA          410210.0   \n",
      "3  Western Dress  ...  753.33   PUDUCHERRY   PUDUCHERRY          605008.0   \n",
      "4            Top  ...  574.00      CHENNAI   TAMIL NADU          600073.0   \n",
      "\n",
      "  ship-country                                      promotion-ids    B2B  \\\n",
      "0           IN                                                NaN  False   \n",
      "1           IN  Amazon PLCC Free-Financing Universal Merchant ...  False   \n",
      "2           IN       IN Core Free Shipping 2015/04/08 23-48-5-108   True   \n",
      "3           IN                                                NaN  False   \n",
      "4           IN                                                NaN  False   \n",
      "\n",
      "  fulfilled-by  Unnamed: 22 Cluster  \n",
      "0    Easy Ship          NaN       3  \n",
      "1    Easy Ship          NaN       3  \n",
      "2          NaN          NaN       3  \n",
      "3    Easy Ship          NaN       3  \n",
      "4          NaN          NaN       3  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Amount  Qty  Cluster  ship-state_ANDHRA PRADESH  ship-state_APO  \\\n",
      "0  647.62    0        3                      False           False   \n",
      "1  406.00    1        3                      False           False   \n",
      "2  329.00    1        3                      False           False   \n",
      "3  753.33    0        3                      False           False   \n",
      "4  574.00    1        3                      False           False   \n",
      "\n",
      "   ship-state_AR  ship-state_ARUNACHAL PRADESH  ship-state_ASSAM  \\\n",
      "0          False                         False             False   \n",
      "1          False                         False             False   \n",
      "2          False                         False             False   \n",
      "3          False                         False             False   \n",
      "4          False                         False             False   \n",
      "\n",
      "   ship-state_Arunachal Pradesh  ship-state_Arunachal pradesh  ...  \\\n",
      "0                         False                         False  ...   \n",
      "1                         False                         False  ...   \n",
      "2                         False                         False  ...   \n",
      "3                         False                         False  ...   \n",
      "4                         False                         False  ...   \n",
      "\n",
      "   ship-city_zirakpur  ship-city_लखनऊ  Category_Bottom  Category_Dupatta  \\\n",
      "0               False           False            False             False   \n",
      "1               False           False            False             False   \n",
      "2               False           False            False             False   \n",
      "3               False           False            False             False   \n",
      "4               False           False            False             False   \n",
      "\n",
      "   Category_Ethnic Dress  Category_Saree  Category_Set  Category_Top  \\\n",
      "0                  False           False          True         False   \n",
      "1                  False           False         False         False   \n",
      "2                  False           False         False         False   \n",
      "3                  False           False         False         False   \n",
      "4                  False           False         False          True   \n",
      "\n",
      "   Category_Western Dress  Category_kurta  \n",
      "0                   False           False  \n",
      "1                   False            True  \n",
      "2                   False            True  \n",
      "3                    True           False  \n",
      "4                   False           False  \n",
      "\n",
      "[5 rows x 9033 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\GitHub Projects\\\\Project Files\\\\Projects\\\\Capstone 3\\\\Amazon Sale Report with Clusters.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head())\n",
    "\n",
    "# Select relevant features\n",
    "features = data[['Amount', 'Qty', 'ship-country', 'ship-state', 'ship-city', 'Category', 'Cluster']]\n",
    "\n",
    "# Create dummy features for categorical variables\n",
    "features_encoded = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "# Display the first few rows of the encoded data\n",
    "print(features_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf34bb8-8b92-41df-b80a-30404b409943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index             Order ID      Date                        Status  \\\n",
      "0      0  405-8078784-5731545  04-30-22                     Cancelled   \n",
      "1      1  171-9198151-1101146  04-30-22  Shipped - Delivered to Buyer   \n",
      "2      2  404-0687676-7273146  04-30-22                       Shipped   \n",
      "3      3  403-9615377-8133951  04-30-22                     Cancelled   \n",
      "4      4  407-1069790-7240320  04-30-22                       Shipped   \n",
      "\n",
      "  Fulfilment Sales Channel  ship-service-level    Style              SKU  \\\n",
      "0   Merchant      Amazon.in           Standard   SET389   SET389-KR-NP-S   \n",
      "1   Merchant      Amazon.in           Standard  JNE3781  JNE3781-KR-XXXL   \n",
      "2     Amazon      Amazon.in          Expedited  JNE3371    JNE3371-KR-XL   \n",
      "3   Merchant      Amazon.in           Standard    J0341       J0341-DR-L   \n",
      "4     Amazon      Amazon.in          Expedited  JNE3671  JNE3671-TU-XXXL   \n",
      "\n",
      "        Category  ...  Amount    ship-city   ship-state  ship-postal-code  \\\n",
      "0            Set  ...  647.62       MUMBAI  MAHARASHTRA          400081.0   \n",
      "1          kurta  ...  406.00    BENGALURU    KARNATAKA          560085.0   \n",
      "2          kurta  ...  329.00  NAVI MUMBAI  MAHARASHTRA          410210.0   \n",
      "3  Western Dress  ...  753.33   PUDUCHERRY   PUDUCHERRY          605008.0   \n",
      "4            Top  ...  574.00      CHENNAI   TAMIL NADU          600073.0   \n",
      "\n",
      "  ship-country                                      promotion-ids    B2B  \\\n",
      "0           IN                                                NaN  False   \n",
      "1           IN  Amazon PLCC Free-Financing Universal Merchant ...  False   \n",
      "2           IN       IN Core Free Shipping 2015/04/08 23-48-5-108   True   \n",
      "3           IN                                                NaN  False   \n",
      "4           IN                                                NaN  False   \n",
      "\n",
      "  fulfilled-by  Unnamed: 22 Cluster  \n",
      "0    Easy Ship          NaN       3  \n",
      "1    Easy Ship          NaN       3  \n",
      "2          NaN          NaN       3  \n",
      "3    Easy Ship          NaN       3  \n",
      "4          NaN          NaN       3  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "   Amount  Qty  Cluster  ship-state_ANDHRA PRADESH  ship-state_APO  \\\n",
      "0  647.62    0        3                      False           False   \n",
      "1  406.00    1        3                      False           False   \n",
      "2  329.00    1        3                      False           False   \n",
      "3  753.33    0        3                      False           False   \n",
      "4  574.00    1        3                      False           False   \n",
      "\n",
      "   ship-state_AR  ship-state_ARUNACHAL PRADESH  ship-state_ASSAM  \\\n",
      "0          False                         False             False   \n",
      "1          False                         False             False   \n",
      "2          False                         False             False   \n",
      "3          False                         False             False   \n",
      "4          False                         False             False   \n",
      "\n",
      "   ship-state_Arunachal Pradesh  ship-state_Arunachal pradesh  ...  \\\n",
      "0                         False                         False  ...   \n",
      "1                         False                         False  ...   \n",
      "2                         False                         False  ...   \n",
      "3                         False                         False  ...   \n",
      "4                         False                         False  ...   \n",
      "\n",
      "   ship-city_zirakpur  ship-city_लखनऊ  Category_Bottom  Category_Dupatta  \\\n",
      "0               False           False            False             False   \n",
      "1               False           False            False             False   \n",
      "2               False           False            False             False   \n",
      "3               False           False            False             False   \n",
      "4               False           False            False             False   \n",
      "\n",
      "   Category_Ethnic Dress  Category_Saree  Category_Set  Category_Top  \\\n",
      "0                  False           False          True         False   \n",
      "1                  False           False         False         False   \n",
      "2                  False           False         False         False   \n",
      "3                  False           False         False         False   \n",
      "4                  False           False         False          True   \n",
      "\n",
      "   Category_Western Dress  Category_kurta  \n",
      "0                   False           False  \n",
      "1                   False            True  \n",
      "2                   False            True  \n",
      "3                    True           False  \n",
      "4                   False           False  \n",
      "\n",
      "[5 rows x 9033 columns]\n",
      "     Amount       Qty  Cluster  ship-state_ANDHRA PRADESH  ship-state_APO  \\\n",
      "0 -0.003348 -2.886307        3                      False           False   \n",
      "1 -0.862562  0.304989        3                      False           False   \n",
      "2 -1.136378  0.304989        3                      False           False   \n",
      "3  0.372563 -2.886307        3                      False           False   \n",
      "4 -0.265145  0.304989        3                      False           False   \n",
      "\n",
      "   ship-state_AR  ship-state_ARUNACHAL PRADESH  ship-state_ASSAM  \\\n",
      "0          False                         False             False   \n",
      "1          False                         False             False   \n",
      "2          False                         False             False   \n",
      "3          False                         False             False   \n",
      "4          False                         False             False   \n",
      "\n",
      "   ship-state_Arunachal Pradesh  ship-state_Arunachal pradesh  ...  \\\n",
      "0                         False                         False  ...   \n",
      "1                         False                         False  ...   \n",
      "2                         False                         False  ...   \n",
      "3                         False                         False  ...   \n",
      "4                         False                         False  ...   \n",
      "\n",
      "   ship-city_zirakpur  ship-city_लखनऊ  Category_Bottom  Category_Dupatta  \\\n",
      "0               False           False            False             False   \n",
      "1               False           False            False             False   \n",
      "2               False           False            False             False   \n",
      "3               False           False            False             False   \n",
      "4               False           False            False             False   \n",
      "\n",
      "   Category_Ethnic Dress  Category_Saree  Category_Set  Category_Top  \\\n",
      "0                  False           False          True         False   \n",
      "1                  False           False         False         False   \n",
      "2                  False           False         False         False   \n",
      "3                  False           False         False         False   \n",
      "4                  False           False         False          True   \n",
      "\n",
      "   Category_Western Dress  Category_kurta  \n",
      "0                   False           False  \n",
      "1                   False            True  \n",
      "2                   False            True  \n",
      "3                    True           False  \n",
      "4                   False           False  \n",
      "\n",
      "[5 rows x 9033 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\user\\\\Desktop\\\\GitHub Projects\\\\Project Files\\\\Projects\\\\Capstone 3\\\\Amazon Sale Report with Clusters.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head())\n",
    "\n",
    "# Select relevant features\n",
    "features = data[['Amount', 'Qty', 'ship-country', 'ship-state', 'ship-city', 'Category', 'Cluster']]\n",
    "\n",
    "# Create dummy features for categorical variables\n",
    "features_encoded = pd.get_dummies(features, drop_first=True)\n",
    "\n",
    "# Display the first few rows of the encoded data\n",
    "print(features_encoded.head())\n",
    "\n",
    "# Standardize the numeric features\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['Amount', 'Qty']\n",
    "features_encoded[numeric_cols] = scaler.fit_transform(features_encoded[numeric_cols])\n",
    "\n",
    "# Display the first few rows of the scaled data\n",
    "print(features_encoded.head())\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "X = features_encoded.drop(columns=['Cluster'])\n",
    "y = features_encoded['Cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the preprocessed training and testing datasets to CSV files\n",
    "X_train.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GitHub Projects\\\\Project Files\\\\Projects\\\\Capstone 3\\\\X_train.csv', index=False)\n",
    "X_test.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GitHub Projects\\\\Project Files\\\\Projects\\\\Capstone 3\\\\X_test.csv', index=False)\n",
    "y_train.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GitHub Projects\\\\Project Files\\\\Projects\\\\Capstone 3\\\\y_train.csv', index=False)\n",
    "y_test.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GitHub Projects\\\\Project Files\\\\Projects\\\\Capstone 3\\\\y_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdd839c-e0c5-4f64-8ae8-4939829b9c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before transformation: Index(['Amount', 'Qty', 'Category', 'Cluster'], dtype='object')\n",
      "Columns after transformation: Index(['Amount', 'Qty', 'Category_Bottom', 'Category_Dupatta',\n",
      "       'Category_Ethnic Dress', 'Category_Saree', 'Category_Set',\n",
      "       'Category_Top', 'Category_Western Dress', 'Category_kurta', 'Cluster_1',\n",
      "       'Cluster_2', 'Cluster_3'],\n",
      "      dtype='object')\n",
      "Columns after preprocessing: Index(['Amount', 'Qty', 'Category_Bottom', 'Category_Dupatta',\n",
      "       'Category_Ethnic Dress', 'Category_Saree', 'Category_Set',\n",
      "       'Category_Top', 'Category_Western Dress', 'Category_kurta', 'Cluster_1',\n",
      "       'Cluster_2', 'Cluster_3'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9852\n",
      "Logistic Regression Test Precision: 0.9705\n",
      "Logistic Regression Test Recall: 0.9852\n",
      "Logistic Regression Test F1 Score: 0.9778\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy: 0.9851\n",
      "Random Forest Test Precision: 0.9705\n",
      "Random Forest Test Recall: 0.9851\n",
      "Random Forest Test F1 Score: 0.9777\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Test Accuracy: 0.9852\n",
      "SVC Test Precision: 0.9705\n",
      "SVC Test Recall: 0.9852\n",
      "SVC Test F1 Score: 0.9778\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the data with Dask in smaller batches\n",
    "file_path = 'C:/Users/user/Desktop/GitHub Projects/Project Files/Projects/Capstone 3/Amazon Sale Report with Clusters.csv'\n",
    "try:\n",
    "    data = dd.read_csv(file_path, blocksize=\"100MB\")  # Adjust blocksize as needed\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# Select relevant features\n",
    "selected_features = ['Amount', 'Qty', 'Category', 'Cluster']\n",
    "features = data[selected_features]\n",
    "\n",
    "# Categorize the relevant columns before creating dummy variables\n",
    "features['Category'] = features['Category'].astype('category')\n",
    "features['Cluster'] = features['Cluster'].astype('category')\n",
    "\n",
    "# Ensure known categories\n",
    "features = features.categorize(columns=['Category', 'Cluster'])\n",
    "\n",
    "# Create dummy features for categorical variables\n",
    "features_encoded = dd.get_dummies(features, drop_first=True)\n",
    "\n",
    "# Verify column names before and after transformation\n",
    "print(\"Columns before transformation:\", features.columns)\n",
    "print(\"Columns after transformation:\", features_encoded.columns)\n",
    "\n",
    "# Handle missing values and standardize the features\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def preprocess_partition(df):\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df_imputed), columns=df.columns)\n",
    "    return df_scaled\n",
    "\n",
    "features_scaled = features_encoded.map_partitions(preprocess_partition)\n",
    "\n",
    "# Convert to pandas dataframe for splitting and training\n",
    "features_scaled = features_scaled.compute()\n",
    "\n",
    "# Verify column names after preprocessing\n",
    "print(\"Columns after preprocessing:\", features_scaled.columns)\n",
    "\n",
    "# Combine cluster dummy columns back into a single column\n",
    "features_scaled['Cluster'] = features_scaled[['Cluster_1', 'Cluster_2', 'Cluster_3']].idxmax(axis=1)\n",
    "\n",
    "# Drop the dummy cluster columns from the feature set\n",
    "X = features_scaled.drop(columns=['Cluster_1', 'Cluster_2', 'Cluster_3', 'Cluster'])\n",
    "y = features_scaled['Cluster']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=100)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Random Forest\": random_forest,\n",
    "    \"SVC\": svc\n",
    "}\n",
    "\n",
    "# Train and evaluate the models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"{name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{name} Test Precision: {precision:.4f}\")\n",
    "    print(f\"{name} Test Recall: {recall:.4f}\")\n",
    "    print(f\"{name} Test F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe86f2-c8af-47c7-9931-19cd9c335797",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e449b9-e821-467d-9e49-ac08b4bc8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  feature  importance\n",
      "0                  Amount    0.968393\n",
      "1                     Qty    0.011805\n",
      "6            Category_Set    0.004894\n",
      "7            Category_Top    0.004054\n",
      "9          Category_kurta    0.003070\n",
      "4   Category_Ethnic Dress    0.003063\n",
      "8  Category_Western Dress    0.002975\n",
      "2         Category_Bottom    0.001233\n",
      "5          Category_Saree    0.000491\n",
      "3        Category_Dupatta    0.000022\n"
     ]
    }
   ],
   "source": [
    "importances = random_forest.feature_importances_\n",
    "feature_names = X.columns\n",
    "feature_importances = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf9563c-d1e6-407f-8b30-49c45a033b54",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc27586-8667-40e2-96cf-02b653c16941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression:\n",
      "[[    0     0   356]\n",
      " [    0     0    27]\n",
      " [    0     0 25412]]\n",
      "Classification Report for Logistic Regression:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cluster_1       0.00      0.00      0.00       356\n",
      "   Cluster_2       0.00      0.00      0.00        27\n",
      "   Cluster_3       0.99      1.00      0.99     25412\n",
      "\n",
      "    accuracy                           0.99     25795\n",
      "   macro avg       0.33      0.33      0.33     25795\n",
      "weighted avg       0.97      0.99      0.98     25795\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix for Random Forest:\n",
      "[[    0     0   356]\n",
      " [    0     0    27]\n",
      " [    2     0 25410]]\n",
      "Classification Report for Random Forest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cluster_1       0.00      0.00      0.00       356\n",
      "   Cluster_2       0.00      0.00      0.00        27\n",
      "   Cluster_3       0.99      1.00      0.99     25412\n",
      "\n",
      "    accuracy                           0.99     25795\n",
      "   macro avg       0.33      0.33      0.33     25795\n",
      "weighted avg       0.97      0.99      0.98     25795\n",
      "\n",
      "------------------------------\n",
      "Confusion Matrix for SVC:\n",
      "[[    0     0   356]\n",
      " [    0     0    27]\n",
      " [    0     0 25412]]\n",
      "Classification Report for SVC:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Cluster_1       0.00      0.00      0.00       356\n",
      "   Cluster_2       0.00      0.00      0.00        27\n",
      "   Cluster_3       0.99      1.00      0.99     25412\n",
      "\n",
      "    accuracy                           0.99     25795\n",
      "   macro avg       0.33      0.33      0.33     25795\n",
      "weighted avg       0.97      0.99      0.98     25795\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Confusion Matrix for {name}:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Classification Report for {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0a81a-f694-48de-833b-7b4f3d3136d0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bb5c265-bcac-412b-9dec-b2e9681bf62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1}\n",
      "Best score for Logistic Regression: 0.9859081218203\n",
      "------------------------------\n",
      "Best parameters for Random Forest: {'max_depth': 10, 'n_estimators': 200}\n",
      "Best score for Random Forest: 0.9859081221020903\n",
      "------------------------------\n",
      "Best parameters for SVC: {'C': 0.1, 'kernel': 'linear'}\n",
      "Best score for SVC: 0.9859081218203\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
    "    'Random Forest': {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
    "    'SVC': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid[name], cv=3, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best score for {name}: {grid_search.best_score_}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90691d2-4851-4534-9f3e-8a9bfc94500d",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "408567ce-6d17-4497-b1c0-a778c5505f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores for Logistic Regression: [0.98577244 0.98577244 0.98577244 0.98573367 0.98573367]\n",
      "Mean CV Score for Logistic Regression: 0.9857569296375267\n",
      "------------------------------\n",
      "Cross-Validation Scores for Random Forest: [0.9858112  0.94150029 0.9854623  0.9855786  0.98565613]\n",
      "Mean CV Score for Random Forest: 0.9768017057569296\n",
      "------------------------------\n",
      "Cross-Validation Scores for SVC: [0.98577244 0.98577244 0.98577244 0.98573367 0.98573367]\n",
      "Mean CV Score for SVC: 0.9857569296375267\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-Validation Scores for {name}: {scores}\")\n",
    "    print(f\"Mean CV Score for {name}: {scores.mean()}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97918e84-852b-48c2-802c-fb1181fe13a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(log_reg, 'logistic_regression_model.pkl')\n",
    "joblib.dump(random_forest, 'random_forest_model.pkl')\n",
    "joblib.dump(svc, 'svc_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c10eb1-cc31-44d3-8442-16d447754db8",
   "metadata": {},
   "source": [
    "## Key Insights from the Model Results\n",
    "### Feature Importance Analysis:\n",
    "\n",
    "The most important feature is Amount, contributing significantly to the model's predictions.\n",
    "Other features like Qty, Category_Set, and Category_Top have minor importance, indicating they also play a role but are less critical compared to Amount.\n",
    "\n",
    "### Model Performance:\n",
    "\n",
    "All three models (Logistic Regression, Random Forest, and SVC) show high accuracy, precision, recall, and F1 scores.\n",
    "However, there is an imbalance in the prediction of clusters. Cluster 3 is predicted with high accuracy, while Clusters 1 and 2 are not predicted correctly at all.\n",
    "\n",
    "### Hyperparameter Tuning:\n",
    "\n",
    "The best hyperparameters for Logistic Regression include C=0.1.\n",
    "For Random Forest, the best parameters are max_depth=10 and n_estimators=200.\n",
    "Cross-Validation:\n",
    "\n",
    "Cross-validation confirms the stability of the Logistic Regression model with a mean CV score of approximately 0.9858.\n",
    "The Random Forest model also shows stability with a mean CV score of approximately 0.9768."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fab507-70e8-4785-a35a-a559911741c6",
   "metadata": {},
   "source": [
    "## Analysis of the Results\n",
    "The analysis of the sales data using clustering and machine learning models has provided valuable insights into the key factors driving different sales patterns. The primary feature influencing cluster predictions is the sales Amount, with other features like Qty and various product categories playing lesser roles. The high accuracy, precision, recall, and F1 scores of the models—Logistic Regression, Random Forest, and SVC—indicate that the models perform well overall, with an accuracy of approximately 98.5%. However, the confusion matrices reveal that Clusters 1 and 2 are not predicted correctly, suggesting a significant imbalance in the dataset. This imbalance is reflected in the classification reports, where precision and recall for Clusters 1 and 2 are set to zero. The hyperparameter tuning results highlight the optimal settings for each model, further improving their performance. The cross-validation scores confirm the stability of the Logistic Regression and Random Forest models, with mean CV scores of approximately 0.9858 and 0.9768, respectively.\n",
    "\n",
    "### Extended Modeling Plan\n",
    "1. Data Collection:\n",
    "\n",
    "Continuously collect and integrate additional sales data to expand the dataset. This can include new product categories, additional geographical regions, and more granular time-based data to enhance model performance.\n",
    "\n",
    "2. Feature Engineering:\n",
    "\n",
    "Explore additional features that could provide more insights into sales patterns. This includes customer demographics, seasonal trends, and external economic indicators. Utilize advanced feature engineering techniques to create meaningful features that can improve model accuracy.\n",
    "\n",
    "3. Addressing Class Imbalance:\n",
    "\n",
    "Implement techniques to handle class imbalance, such as Synthetic Minority Over-sampling Technique (SMOTE) or Adaptive Synthetic (ADASYN) sampling, to generate synthetic samples for underrepresented clusters. This will help the models learn to predict these clusters more accurately.\n",
    "\n",
    "4. Advanced Modeling Techniques:\n",
    "\n",
    "Experiment with more complex models, such as Gradient Boosting Machines (GBM), XGBoost, or neural networks, to capture intricate patterns in the data. Evaluate these models against the current ones to determine if they offer significant improvements in performance.\n",
    "\n",
    "5. Model Interpretability:\n",
    "\n",
    "Utilize model interpretability tools like SHAP (SHapley Additive exPlanations) to understand the contribution of each feature to the model’s predictions. This will provide deeper insights into the driving factors behind each cluster and help refine the model further.\n",
    "\n",
    "6. Hyperparameter Tuning and Optimization:\n",
    "\n",
    "Continuously refine hyperparameter tuning using techniques like Bayesian Optimization or Random Search to find the best model configurations. This ensures that the models are performing at their optimal settings.\n",
    "\n",
    "7. Continuous Monitoring and Evaluation:\n",
    "\n",
    "Implement a system for continuous monitoring of model performance. This includes setting up pipelines for real-time data updates and periodic re-evaluation of models to ensure they adapt to changing sales patterns. Regularly review model metrics and update models as needed.\n",
    "\n",
    "8. Visualization and Reporting:\n",
    "\n",
    "Enhance the visualization and reporting of results. Develop interactive dashboards in Tableau that allow stakeholders to explore data by clusters, visualize feature importance, and understand model predictions. Regularly update these dashboards to reflect the latest insights and trends.\n",
    "By following this extended modeling plan, we can ensure that the sales prediction models are robust, accurate, and adaptable to new data, providing actionable insights for strategic decision-making. This comprehensive approach will help in understanding the key factors driving sales, enabling targeted marketing strategies, optimized inventory management, and ultimately improving overall sales performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
